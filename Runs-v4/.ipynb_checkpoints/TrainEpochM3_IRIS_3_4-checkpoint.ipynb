{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Impact of Barren Plateaus Mitigation Strategy on the Performance of Quantum Neural Networks\n",
    "*Training QNN treated with method 3 (Identity Blocks) of the BP mitigation strategy (IRIS)*\n",
    "\n",
    "**Authors:**\n",
    "- Jacob Cybulski and Thanh Nguyen\n",
    "\n",
    "**Date:**\n",
    "- June 2023\n",
    "\n",
    "**Data:**\n",
    "- Data = IRIS dataset with 99 examples\n",
    "- Features = 4\n",
    "- Target = {-1, 1}\n",
    "- Iterations = 150\n",
    "- Instance = 10\n",
    "\n",
    "**Description:**\n",
    "- This notebook aims to train 10 instances of a QNN initialised with identity blocks and produce averaged performance stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy, math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from qiskit.utils import algorithm_globals\n",
    "from qiskit.algorithms.optimizers import COBYLA, NELDER_MEAD, SLSQP, SPSA\n",
    "from qiskit.opflow import Z, I, StateFn, PauliExpectation, Gradient, NaturalGradient, PauliSumOp\n",
    "from qiskit.circuit.library import ZZFeatureMap, RealAmplitudes\n",
    "from qiskit_machine_learning.neural_networks import SamplerQNN, EstimatorQNN, OpflowQNN, CircuitQNN, TwoLayerQNN\n",
    "from qiskit_machine_learning.algorithms.classifiers import VQC, NeuralNetworkClassifier\n",
    "from qiskit.quantum_info import SparsePauliOp\n",
    "from qiskit_machine_learning.connectors import TorchConnector\n",
    "\n",
    "# Set seed for random generators\n",
    "# algorithm_globals.random_seed = 42\n",
    "\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Components.circuits import preTrainedBlockGenerator, layerwise_training, featureMapGenerator, AnsatzGenerator\n",
    "from Components.data import iris, fetch_mnist\n",
    "from Components.utils import plot_loss, score, parity, classification_callback, plot_objfn_range, result_to_objfun_dataframes, save_results\n",
    "from Components.train import create_qnn, sampling_experiment, train, train_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_SIZE = 99\n",
    "FEATURE_DIM = 4\n",
    "MAX_ITER = 150\n",
    "MAX_INST = 10\n",
    "\n",
    "MAX_REPS = 9\n",
    "MIN_REPS = 1\n",
    "MAX_IDENTITIES_BLOCKS = 2  # <---- Number of identity blocks, depth values of identity blocks is close to that of normal ansatz (5 qubits)\n",
    "ENTANGLEMENT = 'linear'\n",
    "\n",
    "GLOBAL_OPERATOR = PauliSumOp.from_list([('Z'*FEATURE_DIM, 1)])\n",
    "LOCAL_OPERATOR = PauliSumOp.from_list([('I' * (FEATURE_DIM - 2)+'Z'*2, 1)])\n",
    "\n",
    "LOG_PATH = './Logs-IRIS-v4'\n",
    "METHOD_TAG = 'm3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_val, y_train, y_val = fetch_mnist_balanced(PCA_n = FEATURE_DIM, data_size=DATA_SIZE)\n",
    "# X_train, X_val, y_train, y_val = fetch_mnist(PCA_n = FEATURE_DIM, data_size=DATA_SIZE)\n",
    "X_train, X_val, y_train, y_val = iris(pd=False, PCA_n=None)\n",
    "\n",
    "X_train_t = torch.from_numpy(X_train).to(torch.float32)\n",
    "y_train_t = torch.from_numpy(y_train).to(torch.float32)\n",
    "X_val_t = torch.from_numpy(X_val).to(torch.float32)\n",
    "y_val_t = torch.from_numpy(y_val).to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot dataset (only the first two args)\n",
    "for x, y_target in zip(X_train_t, y_train_t):\n",
    "    if y_target == 1:\n",
    "        plt.plot(x[0], x[1], \"bo\")\n",
    "    else:\n",
    "        plt.plot(x[0], x[1], \"go\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_method_data(data, title='Instance Losses', dlabel='inst#', xlabel='Loss', ylabel='Iteration'):\n",
    "    # create figure and axis\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_figheight(4)\n",
    "    fig.set_figwidth(8)\n",
    "    \n",
    "    # setting the axis' labels\n",
    "    ax.set_ylabel(xlabel)\n",
    "    ax.set_xlabel(ylabel)\n",
    "\n",
    "    # Plot data\n",
    "    for i in range(len(data)):\n",
    "        data[i].T.plot(ax=ax, label=f'inst# {i}', figsize=(5, 3))\n",
    "    ax.legend([f'{dlabel} {i}' for i in range(len(data))])\n",
    "    plt.title(title)\n",
    "    plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 3 (Identity Blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit.primitives import Estimator # Statevector estimator\n",
    "from os.path import exists\n",
    "from os import makedirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_map = featureMapGenerator(FEATURE_DIM)\n",
    "identity_block = preTrainedBlockGenerator(FEATURE_DIM, MAX_IDENTITIES_BLOCKS, overlay=2, entanglement=ENTANGLEMENT, insert_barriers=True)\n",
    "ansatz = identity_block['circuit']\n",
    "qc = feature_map.compose(ansatz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To execute on multiple machines concurrently\n",
    "# Select separate sub-lists of instance numbers and run\n",
    "# Alternatively use range(MAX_INST) for all\n",
    "\n",
    "m = METHOD_TAG\n",
    "path = LOG_PATH\n",
    "\n",
    "# for i in [0, 1, 2, 3, 4, 5, 6, 8, 9]: \n",
    "for i in [3, 4]: \n",
    "    \n",
    "    # Mark that the method's data has been saved\n",
    "    if (exists(f'{path}/{m}')):\n",
    "        print(f'Adding a new instance {i} of method {m}\\n')\n",
    "    else:\n",
    "        makedirs(f'{path}/{m}')\n",
    "        print(f'Creating the first instance {i} of method {m}\\n')\n",
    "        \n",
    "    # The identity block returns parameters in order different to that in the ansatz\n",
    "    identity_block = preTrainedBlockGenerator(FEATURE_DIM, MAX_IDENTITIES_BLOCKS, overlay=2, entanglement=ENTANGLEMENT, insert_barriers=True)\n",
    "    id_dict = {k.name : v for k, v in identity_block['params_values'].items()}\n",
    "    initial_point = [id_dict[p.name] for p in list(ansatz.parameters)]\n",
    "\n",
    "    # By default this will run as a local simulation\n",
    "    qnn = EstimatorQNN(\n",
    "        circuit=qc,\n",
    "        estimator=Estimator(),\n",
    "        observables=GLOBAL_OPERATOR,\n",
    "        input_params=feature_map.parameters,\n",
    "        weight_params=ansatz.parameters\n",
    "    )\n",
    "\n",
    "    model = TorchConnector(qnn, initial_weights=initial_point)\n",
    "\n",
    "    loss_function = nn.L1Loss() # MSELoss()\n",
    "    optimizer = torch.optim.NAdam(model.parameters(), lr=0.05)\n",
    "\n",
    "    model, losses, accuracy_train, accuracy_test, weights = train(\n",
    "        model, \n",
    "        MAX_ITER, \n",
    "        X_train_t,\n",
    "        y_train_t,\n",
    "        X_val_t,\n",
    "        y_val_t,\n",
    "        optimizer = optimizer, \n",
    "        loss_function = loss_function\n",
    "        )\n",
    "\n",
    "    pd.DataFrame(losses).astype('float').to_csv(f'{path}/{m}/{m}-{i}-LossFunction.csv')\n",
    "    pd.DataFrame(accuracy_train).astype('float').to_csv(f'{path}/{m}/{m}-{i}-Scores-Train.csv')\n",
    "    pd.DataFrame(accuracy_test).astype('float').to_csv(f'{path}/{m}/{m}-{i}-Scores-Test.csv')\n",
    "    pd.DataFrame(weights).astype('float').to_csv(f'{path}/{m}/{m}-{i}-Weights.csv')\n",
    "    \n",
    "    # Mark that the method's data has been saved\n",
    "    if (exists(f'{path}/{m}/{m}-Method.csv')):\n",
    "        f = open(f'{path}/{m}/{m}-Method.csv', 'a')\n",
    "    else:\n",
    "        f = open(f'{path}/{m}/{m}-Method.csv', 'w')\n",
    "        f.write(f'{m},Instance,Max Inst,Examples,Features,Iterations\\n')\n",
    "    f.write(f',{i},{MAX_INST},{DATA_SIZE},{FEATURE_DIM},{MAX_ITER}\\n')\n",
    "    f.close()\n",
    "    \n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi'] = 300\n",
    "\n",
    "# Plot the loss of the last saved instance\n",
    "plot_method_data([pd.DataFrame(losses).astype('float').T])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the loss of the last saved instance\n",
    "plot_method_data([pd.DataFrame(accuracy_test).astype('float').T],\n",
    "                title='Test Accuracy', dlabel='inst#', xlabel='Accuraccy', ylabel='Iteration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip list | grep qiskit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip list | grep torch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "6a13c8f5b783206a43b73a673b4c249a5e5ee0a2cf865a54b80fb656bbdf8626"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
