{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measure Capacity of QNN architechture with Effective Dimension analysis\n",
    "\n",
    "References:\n",
    "- QISKIT guide to calculate ED: [Effective Dimension of Qiskit Neural Networks](https://qiskit.org/documentation/machine-learning/tutorials/10_effective_dimension.html)\n",
    "- [The power of quantum neural networks](https://arxiv.org/pdf/2011.00027.pdf)\n",
    "- [Effective dimension of machine learning models](https://arxiv.org/pdf/2112.04807.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'qiskit-terra': '0.23.1', 'qiskit-aer': '0.11.2', 'qiskit-ignis': None, 'qiskit-ibmq-provider': '0.20.0', 'qiskit': '0.41.0', 'qiskit-nature': '0.5.2', 'qiskit-finance': '0.3.4', 'qiskit-optimization': '0.5.0', 'qiskit-machine-learning': '0.5.0'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import qiskit\n",
    "qiskit.__qiskit_version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Fisher Information matrix reflects how sensitive a neural network's output to change in the network's parameter space.\n",
    "Effective dimension uses Fisher Information matrix to measure capacity of NNs.\n",
    "\n",
    "Steps as follows:\n",
    "- Define a neural network\n",
    "- Define a series of inputs and weight samples.\n",
    "- Use `EffectiveDimension` class to calculate effective dimension\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from os.path import exists\n",
    "from os import makedirs\n",
    "\n",
    "from qiskit import Aer, IBMQ\n",
    "from qiskit.utils import QuantumInstance\n",
    "from qiskit.utils import algorithm_globals\n",
    "from qiskit.algorithms.optimizers import COBYLA, NELDER_MEAD, SLSQP, SPSA\n",
    "from qiskit.opflow import Z, X, I, StateFn, PauliExpectation, Gradient, PauliSumOp\n",
    "from qiskit_machine_learning.neural_networks import SamplerQNN, EstimatorQNN, OpflowQNN\n",
    "from qiskit_machine_learning.neural_networks import EffectiveDimension\n",
    "from qiskit_machine_learning.algorithms.classifiers import VQC, NeuralNetworkClassifier\n",
    "from qiskit.quantum_info import SparsePauliOp\n",
    "from qiskit_machine_learning.neural_networks import EffectiveDimension, LocalEffectiveDimension\n",
    "from qiskit.primitives import Estimator # Statevector estimator\n",
    "\n",
    "from Components.circuits import preTrainedBlockGenerator, layerwise_training, featureMapGenerator, AnsatzGenerator\n",
    "from Components.data import iris, fetch_mnist_balanced\n",
    "from Components.utils import plot_loss, score, parity, classification_callback, plot_objfn_range, result_to_objfun_dataframes, save_results\n",
    "from Components.train import create_qnn, sampling_experiment\n",
    "\n",
    "from qiskit.providers.fake_provider import FakeVigo, FakePerth\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi'] = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Components.log_ops import plot_method_data\n",
    "from Components.log_ops import logs_to_methods_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings for experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "FEATURE_DIM = 4\n",
    "max_qubit = FEATURE_DIM\n",
    "MAX_REPS = 9\n",
    "MIN_REPS = 1\n",
    "MAX_IDENTITIES_BLOCKS = 2\n",
    "ENTANGLEMENT = 'linear'\n",
    "\n",
    "MAX_ITER = 150\n",
    "MAX_INST = 10\n",
    "ITER_STEP = 25\n",
    "GLOBAL_INPUT_SAMPLES = 20\n",
    "GLOBAL_WEIGHT_SAMPLES = 20\n",
    "GLOBAL_OPERATOR = PauliSumOp.from_list([('Z'*FEATURE_DIM, 1)])\n",
    "LOCAL_OPERATOR = PauliSumOp.from_list([('I' * (FEATURE_DIM - 2)+'Z'*2, 1)])\n",
    "\n",
    "\n",
    "# define ranges to test different numbers of data\n",
    "n = [75, 90, 105, 120, 135, 150, 200, 300, 400, 1000, 5000, 8000, 10000, 40000, 60000, 100000, 150000, 200000, 500000, 1000000]\n",
    "\n",
    "# use user defined data\n",
    "iris_df = iris(pd=True).drop(columns='target')\n",
    "# mnist_df = fetch_mnist_balanced(PCA_n = FEATURE_DIM, data_size=100, split=False)[0]\n",
    "input_samples = iris_df.to_numpy()\n",
    "\n",
    "### Select a data set and its folder\n",
    "LOGS_PATH = './Logs-IRIS-v4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of a valid archive: ./Logs-IRIS-v4\n",
      "   Found method: m0\n",
      "      Found method instance: m0-0\n",
      "         ... Instance m0-0 renumbered as 0\n",
      "      Found method instance: m0-1\n",
      "         ... Instance m0-1 renumbered as 1\n",
      "      Found method instance: m0-2\n",
      "         ... Instance m0-2 renumbered as 2\n",
      "      Found method instance: m0-3\n",
      "         ... Instance m0-3 renumbered as 3\n",
      "      Found method instance: m0-4\n",
      "         ... Instance m0-4 renumbered as 4\n",
      "      Found method instance: m0-5\n",
      "         ... Instance m0-5 renumbered as 5\n",
      "      Found method instance: m0-6\n",
      "         ... Instance m0-6 renumbered as 6\n",
      "      Found method instance: m0-7\n",
      "         ... Instance m0-7 renumbered as 7\n",
      "      Found method instance: m0-8\n",
      "         ... Instance m0-8 renumbered as 8\n",
      "      Found method instance: m0-9\n",
      "         ... Instance m0-9 renumbered as 9\n",
      "      Method m0 had 10 valid, 0 missing, and 0 in error instances\n",
      "   Found method: m1\n",
      "      Found method instance: m1-0\n",
      "         ... Instance m1-0 renumbered as 0\n",
      "      Found method instance: m1-1\n",
      "         ... Instance m1-1 renumbered as 1\n",
      "      Found method instance: m1-2\n",
      "         ... Instance m1-2 renumbered as 2\n",
      "      Found method instance: m1-3\n",
      "         ... Instance m1-3 renumbered as 3\n",
      "      Found method instance: m1-4\n",
      "         ... Instance m1-4 renumbered as 4\n",
      "      Found method instance: m1-5\n",
      "         ... Instance m1-5 renumbered as 5\n",
      "      Found method instance: m1-6\n",
      "         ... Instance m1-6 renumbered as 6\n",
      "      Found method instance: m1-7\n",
      "         ... Instance m1-7 renumbered as 7\n",
      "      Found method instance: m1-8\n",
      "         ... Instance m1-8 renumbered as 8\n",
      "      Found method instance: m1-9\n",
      "         ... Instance m1-9 renumbered as 9\n",
      "      Method m1 had 10 valid, 0 missing, and 0 in error instances\n",
      "   Found method: m2\n",
      "      Found method instance: m2-0\n",
      "         ... Instance m2-0 renumbered as 0\n",
      "      Found method instance: m2-1\n",
      "         ... Instance m2-1 renumbered as 1\n",
      "      Found method instance: m2-2\n",
      "         ... Instance m2-2 renumbered as 2\n",
      "      Found method instance: m2-3\n",
      "         ... Instance m2-3 renumbered as 3\n",
      "      Found method instance: m2-4\n",
      "         ... Instance m2-4 renumbered as 4\n",
      "      Found method instance: m2-5\n",
      "         ... Instance m2-5 renumbered as 5\n",
      "      Found method instance: m2-6\n",
      "         ... Instance m2-6 renumbered as 6\n",
      "      Found method instance: m2-7\n",
      "         ... Instance m2-7 renumbered as 7\n",
      "      Found method instance: m2-8\n",
      "         ... Instance m2-8 renumbered as 8\n",
      "      Found method instance: m2-9\n",
      "         ... Instance m2-9 renumbered as 9\n",
      "      Method m2 had 10 valid, 0 missing, and 0 in error instances\n",
      "   Found method: m3\n",
      "      Found method instance: m3-0\n",
      "         ... Instance m3-0 renumbered as 0\n",
      "      Found method instance: m3-1\n",
      "         ... Instance m3-1 renumbered as 1\n",
      "      Found method instance: m3-2\n",
      "         ... Instance m3-2 renumbered as 2\n",
      "      Found method instance: m3-3\n",
      "         ... Instance m3-3 renumbered as 3\n",
      "      Found method instance: m3-4\n",
      "         ... Instance m3-4 renumbered as 4\n",
      "      Found method instance: m3-5\n",
      "         ... Instance m3-5 renumbered as 5\n",
      "      Found method instance: m3-6\n",
      "         ... Instance m3-6 renumbered as 6\n",
      "      Found method instance: m3-7\n",
      "         ... Instance m3-7 renumbered as 7\n",
      "      Found method instance: m3-8\n",
      "         ... Instance m3-8 renumbered as 8\n",
      "      Found method instance: m3-9\n",
      "         ... Instance m3-9 renumbered as 9\n",
      "      Method m3 had 10 valid, 0 missing, and 0 in error instances\n",
      "\n",
      "\n",
      "Methods found: m0, m1, m2, m3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# trained weights\n",
    "_, weights, _, _ = logs_to_methods_data(LOGS_PATH)\n",
    "\n",
    "print(f'\\n\\nMethods found: {\", \".join(list(weights.keys()))}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Global effective dimension\n",
    "\n",
    "def get_global_ed(qnn):\n",
    "    # weight_samples = algorithm_globals.random.uniform(0, 1, size=(10, qnn.num_weights))\n",
    "\n",
    "    global_ed = EffectiveDimension(\n",
    "        qnn=qnn, \n",
    "        weight_samples=GLOBAL_WEIGHT_SAMPLES, \n",
    "        input_samples=GLOBAL_INPUT_SAMPLES\n",
    "        )\n",
    "        \n",
    "    return global_ed\n",
    "\n",
    "def get_local_ed_loop(qnn, weight_samples, input_samples, dataset_size, step_size=25):\n",
    "    local_ed_list = []\n",
    "    for i in range(0, len(weight_samples), step_size):\n",
    "        local_ed = LocalEffectiveDimension(\n",
    "            qnn=qnn, \n",
    "            weight_samples=weight_samples.iloc[i], \n",
    "            input_samples=input_samples\n",
    "        )\n",
    "        local_eff_dim = local_ed.get_effective_dimension(dataset_size=dataset_size)\n",
    "        local_ed_list.append(local_eff_dim)\n",
    "        print(f'Iteration: {i}; Local E-D: {local_eff_dim}\\n')\n",
    "\n",
    "    return local_ed_list\n",
    "\n",
    "def get_local_ed_loop_v1(qnn, weight_samples, input_samples, dataset_size, step_size=25):\n",
    "    local_ed_list = []\n",
    "    for i in range(0, len(weight_samples), step_size):\n",
    "        local_ed = LocalEffectiveDimension(\n",
    "            qnn=qnn, \n",
    "            weight_samples=weight_samples.iloc[i], \n",
    "            input_samples=input_samples\n",
    "        )\n",
    "        local_eff_dim = local_ed.get_effective_dimension(dataset_size=dataset_size)\n",
    "        local_ed_list.append(local_eff_dim)\n",
    "        print(f'Iteration: {i}; Local E-D: {local_eff_dim}\\n')\n",
    "\n",
    "    return local_ed_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return the number of perameters per weights recording\n",
    "def weights_no(weights):\n",
    "    return len(weights[0].columns)\n",
    "\n",
    "# Calculate global effective dimension\n",
    "def calc_global_ed(features, reps, ops, n):\n",
    "    feature_map = featureMapGenerator(features)\n",
    "    ansatz = AnsatzGenerator(features, reps=reps)\n",
    "    qc = feature_map.compose(ansatz)\n",
    "\n",
    "    qnn = EstimatorQNN(\n",
    "        circuit=qc,\n",
    "        observables=ops,\n",
    "        input_params=list(feature_map.parameters),\n",
    "        weight_params=list(ansatz.parameters)\n",
    "    )\n",
    "    \n",
    "    global_ed = get_global_ed(qnn=qnn)\n",
    "    global_eff = global_ed.get_effective_dimension(dataset_size=n)\n",
    "    \n",
    "    return global_eff\n",
    "\n",
    "# Calculate lolcal effective dimension\n",
    "def calc_local_ed(features, reps, ops, n, weights, input_samples, feature_map=None, ansatz=None):\n",
    "    if(feature_map == None): feature_map = featureMapGenerator(features)\n",
    "    if(ansatz == None): ansatz = AnsatzGenerator(features, reps=reps)\n",
    "    qc = feature_map.compose(ansatz)\n",
    "\n",
    "    qnn = EstimatorQNN(\n",
    "        circuit=qc,\n",
    "        estimator=Estimator(),\n",
    "        observables=ops,\n",
    "        input_params=list(feature_map.parameters),\n",
    "        weight_params=list(ansatz.parameters)\n",
    "    )\n",
    "    \n",
    "    local_eff = []\n",
    "    for i in range(len(weights)):\n",
    "        print(f'Weight sample {len(local_eff)}')\n",
    "        local_eff_inst = get_local_ed_loop(qnn, weights[i], input_samples, n, step_size=ITER_STEP)\n",
    "        local_eff.append(local_eff_inst)\n",
    "        clear_output(wait=True)\n",
    "        \n",
    "    return local_eff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ed_plot(method, method_name, d, iter_step):\n",
    "    fig, axs = plt.subplots(2)\n",
    "    fig.set_figheight(11)\n",
    "    fig.set_figwidth(8)\n",
    "    fig.tight_layout(h_pad=4)\n",
    "    fig.subplots_adjust(top=0.9)\n",
    "    fig.suptitle(f'Effective Dimension / {method} - {method_name}', y=0.95)\n",
    "\n",
    "    axs[0].set_title(f'Method \"{method}\", d={d}')\n",
    "    axs[0].set_xlabel(\"Number of data\")\n",
    "    axs[0].set_ylabel(\"Normalised GLOBAL Effective dimension\")\n",
    "    axs[0].plot(n, np.array(global_eff) / d)\n",
    "    axs[0].semilogx()\n",
    "\n",
    "    axs[1].set_title(f'Method \"{method}\", d={d}')\n",
    "    axs[1].set_xlabel(\"Number of data\")\n",
    "    axs[1].set_ylabel(\"Normalized LOCAL effective dimension\")\n",
    "    for i in range(len(local_eff[0])):\n",
    "        axs[1].plot(n, np.array(local_eff[0][i]) / d)\n",
    "    axs[1].legend([f\"iter# {i*iter_step}\" for i in range(len(local_eff[0]))])\n",
    "         # loc='lower center', bbox_to_anchor=(0.5, -0.25),\n",
    "         # ncol=3, fancybox=True, fontsize='small')\n",
    "\n",
    "    axs[1].semilogx()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 0 Effective Dim (Generic - No BP Strategy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method m0 - Generic Without Any BP Strategy:\n",
      "\tdim=40, inst_no=10, reps=9, ops=ZZZZ\n"
     ]
    }
   ],
   "source": [
    "method = 'm0'\n",
    "method_name = 'Generic Without Any BP Strategy'\n",
    "operator = GLOBAL_OPERATOR\n",
    "reps = MAX_REPS\n",
    "d = weights_no(weights[method])\n",
    "inst_no = len(weights[method])\n",
    "print(f'Method {method} - {method_name}:\\n'+\n",
    "      f'\\tdim={d}, inst_no={inst_no}, reps={reps}, ops={str(operator.to_pauli_op())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_eff = calc_global_ed(FEATURE_DIM, reps, operator, n)\n",
    "local_eff = calc_local_ed(FEATURE_DIM, reps, operator, n, \n",
    "                          weights[method], input_samples)\n",
    "ed_plot(method, method_name, weights_no(weights[method]), ITER_STEP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = method\n",
    "log_path = LOGS_PATH\n",
    "df = pd.DataFrame(global_eff)\n",
    "\n",
    "if (not exists(log_path)):\n",
    "    print(f'Invalid archive: {log_path}')\n",
    "else:\n",
    "    if (not exists(f'{log_path}/{m}')):\n",
    "        print(f'{\" \"*3}Missing method: {m}, creating the method')\n",
    "        makedirs(f'{log_path}/{m}')\n",
    "        \n",
    "    df.to_csv(f'{log_path}/{m}/{m}-GlobalED.csv')\n",
    "    for l in range(len(local_eff)):\n",
    "        df = pd.DataFrame(local_eff[l])\n",
    "        df.to_csv(f'{log_path}/{m}/{m}-{l}-LocalED.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1 Effective Dim (Local Cost Function and Shallow Depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'm1'\n",
    "method_name = 'Local Cost Function and Shallow Depth'\n",
    "operator = LOCAL_OPERATOR\n",
    "reps = MIN_REPS\n",
    "d = weights_no(weights[method])\n",
    "inst_no = len(weights[method])\n",
    "print(f'Method {method} - {method_name}:\\n'+\n",
    "      f'\\tdim={d}, inst_no={inst_no}, reps={reps}, ops={str(operator.to_pauli_op())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "global_eff = calc_global_ed(FEATURE_DIM, reps, operator, n)\n",
    "local_eff = calc_local_ed(FEATURE_DIM, reps, operator, n, \n",
    "                          weights[method], input_samples)\n",
    "ed_plot(method, method_name, weights_no(weights[method]), ITER_STEP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = method\n",
    "log_path = LOGS_PATH\n",
    "df = pd.DataFrame(global_eff)\n",
    "\n",
    "if (not exists(log_path)):\n",
    "    print(f'Invalid archive: {log_path}')\n",
    "else:\n",
    "    print(f'Found a vvalid archive: {log_path}')\n",
    "    if (not exists(f'{log_path}/{m}')):\n",
    "        print(f'{\" \"*3}Missing method: {m}, creating the method')\n",
    "        makedirs(f'{log_path}/{m}')\n",
    "        \n",
    "    print(f'{\" \"*3}Saving global effective dimension: {m}')\n",
    "    df.to_csv(f'{log_path}/{m}/{m}-GlobalED.csv')\n",
    "    print(f'{\" \"*3}Saving global effective dimension: {m} ({len(local_eff)} instances)')\n",
    "    for l in range(len(local_eff)):\n",
    "        df = pd.DataFrame(local_eff[l])\n",
    "        df.to_csv(f'{log_path}/{m}/{m}-{l}-LocalED.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2 Effective Dim (Layerwise Learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'm2'\n",
    "method_name = 'Layerwise Learning'\n",
    "operator = GLOBAL_OPERATOR\n",
    "reps = MAX_REPS\n",
    "d = weights_no(weights[method])\n",
    "inst_no = len(weights[method])\n",
    "print(f'Method {method} - {method_name}:\\n'+\n",
    "      f'\\tdim={d}, inst_no={inst_no}, reps={reps}, ops={str(operator.to_pauli_op())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "global_eff = calc_global_ed(FEATURE_DIM, reps, operator, n)\n",
    "local_eff = calc_local_ed(FEATURE_DIM, reps, operator, n, \n",
    "                          weights[method], input_samples)\n",
    "ed_plot(method, method_name, weights_no(weights[method]), ITER_STEP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = method\n",
    "log_path = LOGS_PATH\n",
    "df = pd.DataFrame(global_eff)\n",
    "\n",
    "if (not exists(log_path)):\n",
    "    print(f'Invalid archive: {log_path}')\n",
    "else:\n",
    "    if (not exists(f'{log_path}/{m}')):\n",
    "        print(f'{\" \"*3}Missing method: {m}, creating the method')\n",
    "        makedirs(f'{log_path}/{m}')\n",
    "        \n",
    "    df.to_csv(f'{log_path}/{m}/{m}-GlobalED.csv')\n",
    "    for l in range(len(local_eff)):\n",
    "        df = pd.DataFrame(local_eff[l])\n",
    "        df.to_csv(f'{log_path}/{m}/{m}-{l}-LocalED.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 3 Effective Dim (Identity Blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'm3'\n",
    "method_name = 'Identity Blocks'\n",
    "operator = GLOBAL_OPERATOR\n",
    "reps = MAX_REPS\n",
    "d = weights_no(weights[method])\n",
    "inst_no = len(weights[method])\n",
    "print(f'Method {method} - {method_name}:\\n'+\n",
    "      f'\\tdim={d}, inst_no={inst_no}, reps={reps}, ops={str(operator.to_pauli_op())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "identity_block = preTrainedBlockGenerator(FEATURE_DIM, MAX_IDENTITIES_BLOCKS, overlay=2, entanglement=ENTANGLEMENT, insert_barriers=True)\n",
    "ansatz = identity_block['circuit']\n",
    "\n",
    "global_eff = calc_global_ed(FEATURE_DIM, reps, operator, n)\n",
    "local_eff = calc_local_ed(FEATURE_DIM, reps, operator, n, \n",
    "                          weights[method], input_samples, ansatz=ansatz)\n",
    "ed_plot(method, method_name, weights_no(weights[method]), ITER_STEP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = method\n",
    "log_path = LOGS_PATH\n",
    "df = pd.DataFrame(global_eff)\n",
    "\n",
    "if (not exists(log_path)):\n",
    "    print(f'Invalid archive: {log_path}')\n",
    "else:\n",
    "    if (not exists(f'{log_path}/{m}')):\n",
    "        print(f'{\" \"*3}Missing method: {m}, creating the method')\n",
    "        makedirs(f'{log_path}/{m}')\n",
    "        \n",
    "    df.to_csv(f'{log_path}/{m}/{m}-GlobalED.csv')\n",
    "    for l in range(len(local_eff)):\n",
    "        df = pd.DataFrame(local_eff[l])\n",
    "        df.to_csv(f'{log_path}/{m}/{m}-{l}-LocalED.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip list | grep qiskit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip list | grep torch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "81e9d827a6bbb46f17f8a3089a2dad663ca51d533d047d0278aae86c4cf6dfb9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
